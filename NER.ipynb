{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9527aef-4afa-41d1-9645-3bec5e17238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets tokenizers seqeval -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c24a3e-dea5-4949-8429-9311f004fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9a507c-50ce-49b8-ace3-6867fe6ca110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "import numpy as np \n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import DataCollatorForTokenClassification \n",
    "from transformers import AutoModelForTokenClassification \n",
    "conll2003 = datasets.load_dataset(\"conll2003\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e759688a-cfb3-47c7-8560-8ba311d05e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ca9b51-a1f3-4d94-a898-aee763443997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b5a3ff-b6a6-44ae-be3c-4a4278aa6b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
       " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebdfee8-95a2-4adf-ab92-fc58452be91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41546e2a-dd9e-46c9-aaa0-e3d86f6568f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26aa1b1a-1619-4b4b-8196-4b8c1a70ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603f2432-3841-445e-88a9-46783d9b2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = conll2003['train'][0]\n",
    "\n",
    "tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "print(word_ids)\n",
    "\n",
    "''' As we can see, it returns a list with the same number of elements as our processed input ids,\n",
    "mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. '''\n",
    "\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a1c14d-e839-49f9-bd43-5683f5576884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'eu',\n",
       " 'rejects',\n",
       " 'german',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'british',\n",
       " 'lamb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebadfc17-2018-417c-894d-ef170fb3f2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_text['ner_tags']), len(tokenized_input[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137bf99b-a128-4b08-b43c-05d565b1b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a mismatched between NER tags and input Ids, so we need to mitigate that\n",
    "\n",
    "def tokenize_and_align_labels(examples, label_all_tokens=True): \n",
    "    \"\"\"\n",
    "    Function to tokenize and align labels with respect to the tokens. This function is specifically designed for\n",
    "    Named Entity Recognition (NER) tasks where alignment of the labels is necessary after tokenization.\n",
    "\n",
    "    Parameters:\n",
    "    examples (dict): A dictionary containing the tokens and the corresponding NER tags.\n",
    "                     - \"tokens\": list of words in a sentence.\n",
    "                     - \"ner_tags\": list of corresponding entity tags for each word.\n",
    "                     \n",
    "    label_all_tokens (bool): A flag to indicate whether all tokens should have labels. \n",
    "                             If False, only the first token of a word will have a label, \n",
    "                             the other tokens (subwords) corresponding to the same word will be assigned -100.\n",
    "\n",
    "    Returns:\n",
    "    tokenized_inputs (dict): A dictionary containing the tokenized inputs and the corresponding labels aligned with the tokens.\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n",
    "    labels = [] \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]): \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        previous_word_idx = None \n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None \n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                # set â€“100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token                 \n",
    "                label_ids.append(label[word_idx]) \n",
    "            else: \n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "                # mask the subword representations after the first subword\n",
    "                 \n",
    "            previous_word_idx = word_idx \n",
    "        labels.append(label_ids) \n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba50946-0be3-4fe2-b0e5-e014dd67bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "source": [
    "#Here None is replaced with -100, and -100 is ignored by pytorch while training \n",
    "\n",
    "q = tokenize_and_align_labels(conll2003['train'][4:5]) \n",
    "print(q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0651b04f-dd0e-450f-9681-aa744b808f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "source": [
    "# So before applying the tokenize_and_align_labels() the tokenized_input has 3 keys\n",
    "# input_ids\n",
    "# token_type_ids\n",
    "# attention_mask\n",
    "# But after applying tokenize_and_align_labels() we have an extra key - 'labels'\n",
    "\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]): \n",
    "    print(f\"{token:_<40} {label}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92d39c5-ff0f-45f8-b67b-d04541353e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "497d849b-5b47-4117-839e-806ffc7a416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3b855c-303a-4036-a254-509d559b2d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imtia\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "args = TrainingArguments( \n",
    "\"test-ner\",\n",
    "evaluation_strategy = \"epoch\", \n",
    "learning_rate=2e-5, \n",
    "per_device_train_batch_size=16, \n",
    "per_device_eval_batch_size=16, \n",
    "num_train_epochs=3, \n",
    "weight_decay=0.01, \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b4ae77-87e5-480d-bf88-1c582ccdb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5281122-ef51-4f33-ac65-ad62a2ce0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4171b5-2ba3-4f02-8564-c366119bdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = conll2003['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4693e6a-418d-43bf-8afd-e933d3d4bc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names \n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8884154-4379-46f4-867d-5823f3891b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(2)},\n",
       " 'ORG': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'overall_precision': np.float64(1.0),\n",
       " 'overall_recall': np.float64(1.0),\n",
       " 'overall_f1': np.float64(1.0),\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = [label_list[i] for i in example[\"ner_tags\"]] \n",
    "\n",
    "metric.compute(predictions=[labels], references=[labels]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92146274-1e53-47e1-b765-363d0c3328fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): \n",
    "    \"\"\"\n",
    "    Function to compute the evaluation metrics for Named Entity Recognition (NER) tasks.\n",
    "    The function computes precision, recall, F1 score and accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    eval_preds (tuple): A tuple containing the predicted logits and the true labels.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
    "    \"\"\"\n",
    "    pred_logits, labels = eval_preds \n",
    "    \n",
    "    pred_logits = np.argmax(pred_logits, axis=2) \n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we donâ€™t need to apply the softmax\n",
    "    \n",
    "    # We remove all the values where the label is -100\n",
    "    predictions = [ \n",
    "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
    "        for prediction, label in zip(pred_logits, labels) \n",
    "    ] \n",
    "    \n",
    "    true_labels = [ \n",
    "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
    "       for prediction, label in zip(pred_logits, labels) \n",
    "   ] \n",
    "    results = metric.compute(predictions=predictions, references=true_labels) \n",
    "    return { \n",
    "   \"precision\": results[\"overall_precision\"], \n",
    "   \"recall\": results[\"overall_recall\"], \n",
    "   \"f1\": results[\"overall_f1\"], \n",
    "  \"accuracy\": results[\"overall_accuracy\"], \n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e7bc23-0638-4b96-9926-9c2a3b331af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imtia\\AppData\\Local\\Temp\\ipykernel_5480\\999771.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer( \n",
    "    model, \n",
    "    args, \n",
    "   train_dataset=tokenized_datasets[\"train\"], \n",
    "   eval_dataset=tokenized_datasets[\"validation\"], \n",
    "   data_collator=data_collator, \n",
    "   tokenizer=tokenizer, \n",
    "   compute_metrics=compute_metrics \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d8bc70-c9d0-4cf0-bfa0-1a98f6d2333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 4:47:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.917209</td>\n",
       "      <td>0.930753</td>\n",
       "      <td>0.923931</td>\n",
       "      <td>0.982191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.944177</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>0.985035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.935059</td>\n",
       "      <td>0.945520</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.985496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2634, training_loss=0.07727416265888837, metrics={'train_runtime': 17236.5662, 'train_samples_per_second': 2.444, 'train_steps_per_second': 0.153, 'total_flos': 1020143109346326.0, 'train_loss': 0.07727416265888837, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ceeb30-aaa0-4422-960a-e4a0084a06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b44b7b-4e5e-4fec-9310-5cb67621206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f27a8ca-ae93-4171-88b8-98ce546dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    str(i): label for i,label in enumerate(label_list)\n",
    "}\n",
    "label2id = {\n",
    "    label: str(i) for i,label in enumerate(label_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c672d472-4e8d-424c-ae5e-615b7030e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701cfad3-8fa7-46fa-b006-189723a95a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"ner_model/config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ffe5abd-2a56-4d0d-ac2e-f870d6a3698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"id2label\"] = id2label\n",
    "config[\"label2id\"] = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17557298-fd77-4b25-ab7d-6f2f356c34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(config, open(\"ner_model/config.json\",\"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e72f8c60-17c8-46ba-a240-4dcd596e02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d3525fe-bef9-44bd-8947-5ded6f182ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bae1227-f120-479e-b5db-3783c9b9b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': np.float32(0.99740607), 'index': 1, 'word': 'bill', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': np.float32(0.9985802), 'index': 2, 'word': 'ge', 'start': 5, 'end': 7}, {'entity': 'I-PER', 'score': np.float32(0.9986524), 'index': 3, 'word': '##ats', 'start': 7, 'end': 10}, {'entity': 'B-LOC', 'score': np.float32(0.9981285), 'index': 10, 'word': 'dhaka', 'start': 34, 'end': 39}]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "example = \"Bill geats is a good man lives in Dhaka\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cfed7-aa2f-44e2-b549-0a2d3a707275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80ce25-f7d0-4526-a2da-7eb9b409eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
